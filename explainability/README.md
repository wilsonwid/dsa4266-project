## Explainability in AI Models

For ease of visualisation, it is advised to run this script on Google Colab or Jupyter Notebook. Please refer to
the Huggingface Repositories to load the respective Resnet and CNN models.

Explainability is crucial for understanding and trusting AI models, especially in high-stakes applications. Techniques like **Grad-CAM** help visualize which parts of an input influence the model's predictions, making complex models more transparent.


### This Directory Contains:
1. **Real and Fake Test Images**: A set of images used to test the model's predictions.
2. **Grad-CAM Visualization Script**: A script to generate **Grad-CAM heatmaps** for our ResNet model, revealing which image regions impact the model's decision.

These resources help improve model transparency and interpretability.
