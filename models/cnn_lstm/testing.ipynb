{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilsonwid/.local/share/virtualenvs/dsa4266-project-RvivrvFB/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-06 02:52:22,353\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-06 02:52:23,127\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-06 02:52:23.286101: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 02:52:23.294725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730832743.304311  102377 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730832743.307215  102377 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 02:52:23.318536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Heavily adapted from https://pytorch.org/tutorials/beginner/introyt/trainingyt.html and https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime as dt\n",
    "import argparse\n",
    "import subprocess\n",
    "import ray.cloudpickle as pickle\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "from utils.dataset import VideoDataset\n",
    "from ray import tune, train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from models.cnn_lstm.cnn_lstm import CNN_LSTM\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "main_folder_path = os.getcwd()\n",
    "\n",
    "MODEL_NAME = \"cnn_lstm\"\n",
    "NOW = dt.datetime.now()\n",
    "FILENAME = f\"{NOW.strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "SAVE_DIR = f\"{main_folder_path}/models/cnn_lstm/saved_models\"\n",
    "DATA_FOLDER = \"data\"\n",
    "INF = 100000000.\n",
    "NUM_WORKERS = 8\n",
    "NUM_CLASSES = 2\n",
    "GPUS_PER_TRIAL = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "\n",
    "timestamp = dt.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "writer = SummaryWriter(f\"runs/rcnn_{timestamp}\")\n",
    "\n",
    "def train_model(\n",
    "    config: dict,\n",
    "    epochs: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the model and saves the weights into a `.pt` file.\n",
    "\n",
    "    Args:\n",
    "        epochs (int): Number of epochs.\n",
    "        filename (str): Filename to save the model to.\n",
    "        writer (SummaryWriter): Writer for logs.\n",
    "        config (dict): Ray Tune dictionary.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    writer = SummaryWriter(f\"runs/cnn_lstm_{timestamp}\")\n",
    "    train_dataset = VideoDataset(\n",
    "        root=f\"{main_folder_path}/data/train\", \n",
    "        clip_len=config[\"steps\"]\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset, \n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    val_dataset = VideoDataset(\n",
    "        root=f\"{main_folder_path}/data/validation\", \n",
    "        clip_len=config[\"steps\"]\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset, \n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    model = CNN_LSTM(\n",
    "        input_channels=int(config[\"input_channels\"]),\n",
    "        num_cnn_layers=int(config[\"num_cnn_layers\"]),\n",
    "        num_kernels=int(config[\"num_kernels\"]),\n",
    "        kernel_size=int(config[\"kernel_size\"]),\n",
    "        stride=1,\n",
    "        padding=\"same\",\n",
    "        dropout_prob=float(config[\"dropout_prob\"]),\n",
    "        bias=False,\n",
    "        num_lstm_layers=int(config[\"num_lstm_layers\"]),\n",
    "        hidden_size=int(config[\"hidden_size\"]),\n",
    "        num_classes=NUM_CLASSES,\n",
    "        bidirectional=bool(config[\"bidirectional\"]),\n",
    "        input_shape=(224, 224),\n",
    "        steps=int(config[\"steps\"])\n",
    "    )\n",
    "\n",
    "    print(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    best_vloss = INF\n",
    "\n",
    "    checkpoint = get_checkpoint()\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"rb\") as fp:\n",
    "                checkpoint_state = pickle.load(fp)\n",
    "            start_epoch = checkpoint_state[\"epoch\"]\n",
    "            model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    print(f\"Starting training at epoch: {start_epoch}\")\n",
    "    for epoch in tqdm(range(start_epoch, epochs)):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        model.train()\n",
    "        collected_labels, collected_predictions = [], []\n",
    "        for i, data in tqdm(enumerate(train_loader)):\n",
    "            vid_inputs, labels = data[\"video\"].to(device), data[\"target\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(vid_inputs)\n",
    "            loss = loss_fn(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            collected_labels.append(labels.cpu())\n",
    "            collected_predictions.append(output.argmax(dim=1).cpu())\n",
    "\n",
    "            if i % 10 == 9:\n",
    "                last_loss = running_loss / 10\n",
    "                epoch_f1 = f1_score(torch.cat(collected_labels), torch.cat(collected_predictions), average=\"weighted\")\n",
    "                print(f\"Batch: {i + 1}, Loss: {last_loss}, F1 score: {epoch_f1}\")\n",
    "                tb_x = epoch * len(train_loader) + i + 1\n",
    "\n",
    "                writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "                writer.add_scalar(\"F1 score/train\", epoch_f1, tb_x)\n",
    "\n",
    "                running_loss = 0.\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            collected_labels, collected_predictions = [], []\n",
    "            for i, vdata in enumerate(val_loader):\n",
    "                vid_inputs, labels = vdata[\"video\"].to(device), vdata[\"target\"].to(device)\n",
    "                output = model(vid_inputs)\n",
    "                loss = loss_fn(output, labels)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                collected_labels.append(labels.cpu())\n",
    "                collected_predictions.append(output.argmax(dim=1).cpu())\n",
    "            val_f1 = f1_score(torch.cat(collected_labels), torch.cat(collected_predictions), average=\"weighted\")\n",
    "            print(f\"Validation Loss: {loss.item()}, Validation F1 score: {val_f1}\")\n",
    "\n",
    "        avg_vloss = running_loss / (i + 1)\n",
    "        print(f\"Train Loss: {last_loss}, Val Loss: {avg_vloss}\")\n",
    "\n",
    "        writer.add_scalars(\"Training vs Validation Loss\",\n",
    "                           {\"Train\": last_loss, \"Validation\": avg_vloss},\n",
    "                           epoch + 1)\n",
    "        writer.add_scalars(\"Training vs Validation F1 Score\",\n",
    "                           {\"Train\": epoch_f1, \"Validation\": val_f1},\n",
    "                           epoch + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "\n",
    "\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch,\n",
    "            \"net_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict()\n",
    "        }\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as checkpoint_dir:\n",
    "            data_path = Path(checkpoint_dir) / \"data.pkl\"\n",
    "            with open(data_path, \"wb\")as fp:\n",
    "                pickle.dump(checkpoint_data, fp)\n",
    "            \n",
    "            checkpoint = Checkpoint.from_directory(checkpoint_dir)\n",
    "            train.report({\n",
    "                \"loss\": avg_vloss,\n",
    "                \"f1\": val_f1\n",
    "            }, checkpoint=checkpoint)\n",
    "    \n",
    "    print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"input_channels\": 6,\n",
    "    \"num_cnn_layers\": 8,\n",
    "    \"num_kernels\": 32,\n",
    "    \"kernel_size\": 10,\n",
    "    \"dropout_prob\": 0.25,\n",
    "    \"num_lstm_layers\":5,\n",
    "    \"hidden_size\": 32,\n",
    "    \"bidirectional\": False,\n",
    "    \"steps\": 100,\n",
    "    \"batch_size\": 1,\n",
    "    \"lr\": 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wilsonwid/github-repos/dsa4266-project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilsonwid/.local/share/virtualenvs/dsa4266-project-RvivrvFB/lib/python3.11/site-packages/ray/train/_internal/session.py:652: UserWarning: `get_checkpoint` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Starting training at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilsonwid/.local/share/virtualenvs/dsa4266-project-RvivrvFB/lib/python3.11/site-packages/torch/nn/modules/conv.py:720: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1036.)\n",
      "  return F.conv3d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 0.6946468889713288, F1 score: 0.18461538461538463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20, Loss: 0.693981921672821, F1 score: 0.27199999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 30, Loss: 0.6923047840595246, F1 score: 0.391382687034861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40, Loss: 0.6910820543766022, F1 score: 0.3779580797836376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 0.6937579989433289, F1 score: 0.35498901098901103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 0.6930661618709564, F1 score: 0.3674074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 0.6918929934501648, F1 score: 0.404063492063492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 80, Loss: 0.6917422473430633, F1 score: 0.4230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 90, Loss: 0.6926373183727265, F1 score: 0.405431018771642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 0.6938655734062195, F1 score: 0.4146216835899116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 110, Loss: 0.6927374303340912, F1 score: 0.42746344564526373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 120, Loss: 0.6920586347579956, F1 score: 0.43163289075238764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 0.6956316947937011, F1 score: 0.4077453790049887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 140, Loss: 0.6942847549915314, F1 score: 0.40822981366459626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Loss: 0.6927455484867096, F1 score: 0.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 160, Loss: 0.6937171518802643, F1 score: 0.41173864894795126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 170, Loss: 0.6954814553260803, F1 score: 0.4023456284437533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 180, Loss: 0.6921037495136261, F1 score: 0.41190185617815595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 190, Loss: 0.691452544927597, F1 score: 0.41481096686862834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Loss: 0.6931620240211487, F1 score: 0.41738051974272444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 210, Loss: 0.692848163843155, F1 score: 0.42174024539393223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 220, Loss: 0.6941696107387543, F1 score: 0.4193312944166187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 230, Loss: 0.6917730867862701, F1 score: 0.42916331363667715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 240, Loss: 0.6945922493934631, F1 score: 0.428125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Loss: 0.6923891067504883, F1 score: 0.43375903614457834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 260, Loss: 0.6929994344711303, F1 score: 0.4365610859728507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 270, Loss: 0.6916969299316407, F1 score: 0.4465619366469225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 280, Loss: 0.6923664331436157, F1 score: 0.453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 290, Loss: 0.6922597467899323, F1 score: 0.454472066924046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Loss: 0.6922758400440217, F1 score: 0.4629384576190996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 310, Loss: 0.692800772190094, F1 score: 0.4564838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 320, Loss: 0.6935778319835663, F1 score: 0.45494804973599046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 330, Loss: 0.6945893824100494, F1 score: 0.44934088165976127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 340, Loss: 0.6937411010265351, F1 score: 0.4420540903983792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Loss: 0.692115741968155, F1 score: 0.4451440243444912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 360, Loss: 0.6935293257236481, F1 score: 0.4482365848960209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 370, Loss: 0.6935611844062806, F1 score: 0.4474660822428977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 380, Loss: 0.6940670073032379, F1 score: 0.44654764831590293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 390, Loss: 0.692977923154831, F1 score: 0.44936012462287783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Loss: 0.6954793751239776, F1 score: 0.440990014785409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 410, Loss: 0.6955307185649872, F1 score: 0.43338694795738614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 420, Loss: 0.6916327893733978, F1 score: 0.4446521880958025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 430, Loss: 0.6931079626083374, F1 score: 0.4532862013212786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 440, Loss: 0.6931180536746979, F1 score: 0.45388048257106445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Loss: 0.6933177828788757, F1 score: 0.45150759057121226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 460, Loss: 0.6935235857963562, F1 score: 0.4492400756143668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 470, Loss: 0.6940839529037476, F1 score: 0.4453341491335412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 480, Loss: 0.6930683612823486, F1 score: 0.4444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 490, Loss: 0.6939326584339142, F1 score: 0.44523865192558204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Loss: 0.6926870346069336, F1 score: 0.4460021436227224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 510, Loss: 0.6922154664993286, F1 score: 0.4466513878278584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 520, Loss: 0.6927872121334075, F1 score: 0.4461538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 530, Loss: 0.6933934569358826, F1 score: 0.4494150943396226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 540, Loss: 0.6932486355304718, F1 score: 0.4535797875661837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_model(config, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa4266-project-RvivrvFB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
