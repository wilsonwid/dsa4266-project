{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_eQGxvd8aRy",
    "outputId": "69c51744-6aa1-44da-d368-f84ce6c44afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQW7Z76Z876u"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_--KKUy18pzu"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PbUu7NiA09Q",
    "outputId": "731da713-4a33-4336-c5db-4129a19d825a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_AF92NTo5aw"
   },
   "source": [
    "Let's now count the number of total videos we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJMAZqE-HavC"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_root_path = pathlib.Path(\"./drive/MyDrive/DSA4266 Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZRB1yJQHm5W",
    "outputId": "50379c5c-f7f3-4add-bf0d-be475790ecb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos: 5500\n"
     ]
    }
   ],
   "source": [
    "video_count_train = len(list(dataset_root_path.glob(\"train/*/*.mp4\")))\n",
    "video_count_val = len(list(dataset_root_path.glob(\"validation/*/*.mp4\")))\n",
    "video_count_test = len(list(dataset_root_path.glob(\"test/*/*.mp4\")))\n",
    "video_total = video_count_train + video_count_val + video_count_test\n",
    "print(f\"Total videos: {video_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNUCBLe6HoLY",
    "outputId": "cb58ce08-8cf8-4c5c-a798-d273192f915f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lbooddsyfl.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lbpfomllae.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lcmjyjdbqn.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lclyxqctwg.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lcegpefqvk.mp4')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These filepaths lead to videos, not images.\n",
    "\n",
    "# While our data preparation and processing pipeline had already extracted the frames from the videos\n",
    "# and augmented them, we were unable to upload all the frames to Google Drive due to lack of space.\n",
    "# Uploading all the frames to Google Colab was also especially time-consuming as we had no indication of whether upload was progressing.\n",
    "# Hence, this notebook runs the frame extraction and augmentation code itself and places the resultant images in the Google Colab server.\n",
    "\n",
    "all_video_file_paths = [\n",
    "    path for path in (\n",
    "        list(dataset_root_path.glob(\"train/*/*.mp4\"))\n",
    "        + list(dataset_root_path.glob(\"validation/*/*.mp4\"))\n",
    "        + list(dataset_root_path.glob(\"test/*/*.mp4\"))\n",
    "    ) if not path.name.startswith(\"._\") # .DS_Store\n",
    "]\n",
    "\n",
    "all_video_file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeWXvJSDHpbw",
    "outputId": "ae9042c0-eb26-4fd0-f5d0-df41daa31c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: ['deepfake', 'real'].\n"
     ]
    }
   ],
   "source": [
    "class_labels = sorted({str(path).split(\"/\")[4] for path in all_video_file_paths})\n",
    "label2id = {label: i for i, label in enumerate(class_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(f\"Unique classes: {list(label2id.keys())}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6qmNcvQpXwW"
   },
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45iXS1i-4JgV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# Define CNN model architecture with skip connections\n",
    "\n",
    "def conv_block(x, filter):\n",
    "    # Layer 1\n",
    "    x_skip = x\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])    # Skip connection\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model(hp):\n",
    "    strides = hp.Int('strides', min_value=1, max_value=3, step=2)\n",
    "    kernel_size = hp.Int('kernel_size', min_value=3, max_value=5, step=2)\n",
    "    filters = 64\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(inputs) # add padding\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) # always doing this\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=strides, padding='same')(x)\n",
    "\n",
    "    # number of filters will increase deeper into the model\n",
    "    for i in range(5):\n",
    "        filters = filters << 1\n",
    "        x = conv_block(x, filters)\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid')(x)  # binary\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']) # always use adam\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Jk8UwWTDHtC",
    "outputId": "adb813ac-c291-41e4-ac32-0816c15e258f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1788/1788 [08:57<00:00,  3.32it/s]\n",
      "100%|██████████| 1788/1788 [09:12<00:00,  3.24it/s]\n",
      "100%|██████████| 550/550 [02:46<00:00,  3.31it/s]\n",
      "100%|██████████| 550/550 [02:45<00:00,  3.32it/s]\n",
      "100%|██████████| 412/412 [02:05<00:00,  3.27it/s]\n",
      "100%|██████████| 412/412 [02:10<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# While our data preparation and processing pipeline had already extracted the frames from the videos\n",
    "# and augmented them, we were unable to upload all the frames to Google Drive due to lack of space.\n",
    "# Uploading all the frames to Google Colab was also especially time-consuming as we had no indication of whether upload was progressing.\n",
    "# Hence, this notebook runs the frame extraction and augmentation code itself and places the resultant images in the Google Colab server.\n",
    "\n",
    "# Frame extraction code\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Functions adapted from Junhui's cnn_dev.ipynb\n",
    "# (Print statements removed to allow tqdm to work)\n",
    "\n",
    "pth = \"./drive/MyDrive/DSA4266 Project/\"\n",
    "\n",
    "\n",
    "def load_video(video_name, folder_path=\"../../data/train_sample_videos\"):\n",
    "    video_path = os.path.join(folder_path, video_name)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    return cap\n",
    "\n",
    "\n",
    "def extract_frames(cap, frame_interval=1):\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            resized_frame = cv2.resize(frame, (224, 224)) / 255.0\n",
    "            frames.append(resized_frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def save_frames(frames, output_folder=\"./extracted_frames\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for frame_count, frame in enumerate(frames):\n",
    "        output_path = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(output_path, (frame * 255).astype(\"uint8\"))\n",
    "\n",
    "\n",
    "def extract_and_save_videos(input_dir, output_dir):\n",
    "    filenames = sorted(os.listdir(input_dir))\n",
    "    for filename in tqdm(filenames):\n",
    "        if not filename.endswith((\".mp4\")):\n",
    "            continue\n",
    "        cap = load_video(filename, input_dir)\n",
    "        frames = extract_frames(cap)\n",
    "        video_output_dir = os.path.join(output_dir, filename[:-4])\n",
    "        save_frames(frames, video_output_dir)\n",
    "\n",
    "categories = [\"train\", \"test\", \"validation\"]\n",
    "for cat in categories:\n",
    "    extract_and_save_videos(f\"{pth}{cat}/deepfake\", f\"FRAMES/{cat}_frames/deepfake\")\n",
    "    extract_and_save_videos(f\"{pth}{cat}/real\", f\"FRAMES/{cat}_frames/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOMos0CAeG1k",
    "outputId": "50dda386-69e5-4ef1-ff1c-cebc48d884db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1788/1788 [10:24<00:00,  2.86it/s]\n",
      "100%|██████████| 1788/1788 [10:31<00:00,  2.83it/s]\n",
      "100%|██████████| 412/412 [02:24<00:00,  2.86it/s]\n",
      "100%|██████████| 412/412 [02:25<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Augmentation code\n",
    "\n",
    "import os\n",
    "import random\n",
    "from typing import Any, Callable, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def rotate_frame(frame: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rotates the given `frame` by the angle `angle`.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Original frame to be transformed.\n",
    "        angle (float): Angle to rotate the frame by.\n",
    "\n",
    "    Returns:\n",
    "        Rotated array of type `np.ndarray`.\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(frame, matrix, (width, height))\n",
    "    return rotated\n",
    "\n",
    "\n",
    "def adjust_brightness_contrast(\n",
    "    frame: np.ndarray, brightness: float = 0.0, contrast: float = 0.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adjusts the brightness and contrast of a frame.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Original frame to be transformed.\n",
    "        brightness (float): Amount to increase the brightness by.\n",
    "        contrast (float): Amount fo increase the contrast by.\n",
    "\n",
    "    Returns:\n",
    "        Modified array of type `np.ndarray`.\n",
    "    \"\"\"\n",
    "    frame = np.clip(frame * (1 + contrast / 100.0) + brightness, 0, 255).astype(\n",
    "        np.uint8\n",
    "    )\n",
    "    return frame\n",
    "\n",
    "\n",
    "def flip_frame(frame: np.ndarray, flip_code: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flips the frame.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Original frame to be transformed.\n",
    "        flip_code (int): Flip code; 1 for vertical flip and 0 for horizontal flip.\n",
    "\n",
    "    Returns:\n",
    "        Flipped frame of type `np.ndarray`.\n",
    "    \"\"\"\n",
    "    return cv2.flip(frame, flip_code)\n",
    "\n",
    "\n",
    "def transform(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    transformation: Callable[[np.ndarray, Optional[Any], Optional[Any]], np.ndarray],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Applies a single random transformation to the frame, then saves the result.\n",
    "    Note that there is an identity transformation which keeps the frame the same.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Input path as a string.\n",
    "        output_path (str): Output path as a string.\n",
    "        transformation (Callable[[np.ndarray], np.ndarray])\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    frame = cv2.imread(input_path)\n",
    "    transformed_frame = transformation(frame)\n",
    "    transformed_frame = transformed_frame.astype(np.uint8)\n",
    "    cv2.imwrite(output_path, transformed_frame)\n",
    "\n",
    "\n",
    "def augment_frame(\n",
    "    input_dir: str | bytes | os.PathLike,\n",
    "    output_dir: str | bytes | os.PathLike,\n",
    "    filename: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Augments the frame by applying one random transformation and saves it.\n",
    "    Note that there is an identity transformation which keeps the frame the same.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str | bytes | os.PathLike): Input directory.\n",
    "        output_dir (str | bytes | os.PathLike): Output directory.\n",
    "        filename (str): File to be augmented.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    transformations = [\n",
    "        lambda frame: frame,\n",
    "        lambda frame: rotate_frame(frame, 90),\n",
    "        lambda frame: rotate_frame(frame, 180),\n",
    "        lambda frame: rotate_frame(frame, 270),\n",
    "        lambda frame: adjust_brightness_contrast(frame, brightness=-25),\n",
    "        lambda frame: adjust_brightness_contrast(frame, brightness=25),\n",
    "        lambda frame: adjust_brightness_contrast(frame, contrast=-25),\n",
    "        lambda frame: adjust_brightness_contrast(frame, contrast=25),\n",
    "        lambda frame: flip_frame(frame, 1),\n",
    "        lambda frame: flip_frame(frame, 0),\n",
    "    ]\n",
    "\n",
    "    transformation_fn = random.choice(transformations)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    transform(input_path, output_path, transformation_fn)\n",
    "\n",
    "\n",
    "def augment_frames(\n",
    "    input_dir: str | bytes | os.PathLike, output_dir: str | bytes | os.PathLike\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Augments frames by applying a random augmentation to each one.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str | bytes | os.PathLike): Input directory containing the original frames.\n",
    "        output_dir (str | bytes | os.PathLike): Output directory to save the augmented frames to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    filenames = sorted(os.listdir(input_dir))\n",
    "    random.seed(42)\n",
    "    for filename in tqdm(filenames):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        video_dir = os.path.join(input_dir, filename)\n",
    "        video_output_dir = os.path.join(output_dir, filename)\n",
    "        frames = sorted(os.listdir(video_dir))\n",
    "        for frame in frames:\n",
    "            augment_frame(video_dir, video_output_dir, frame)\n",
    "\n",
    "\n",
    "categories = [\"train\", \"validation\"]\n",
    "for cat in categories:\n",
    "    augment_frames(\n",
    "        f\"FRAMES/{cat}_frames/deepfake\", f\"AUGMENTED/{cat}_frames_augmented/deepfake\"\n",
    "    )\n",
    "    augment_frames(f\"FRAMES/{cat}_frames/real\", f\"AUGMENTED/{cat}_frames_augmented/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9RhgHJ0WZ8UF",
    "outputId": "1c34a592-17f8-46fa-9177-85c829a966da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1062283 files belonging to 2 classes.\n",
      "Found 244142 files belonging to 2 classes.\n",
      "Found 326064 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"AUGMENTED/train_frames_augmented/\",\n",
    "    labels=\"inferred\",  # Automatically labels based on subdirectory names\n",
    "    label_mode=\"binary\",  # For binary classification (0 and 1)\n",
    "    batch_size=32,  # Set your batch size\n",
    "    image_size=(224, 224),  # Resize images to a consistent size (e.g., 224x224)\n",
    "    shuffle=True,  # Shuffle the dataset\n",
    "    seed=42  # Set a seed for reproducibility\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"AUGMENTED/validation_frames_augmented/\",\n",
    "    labels=\"inferred\",  # Automatically labels based on subdirectory names\n",
    "    label_mode=\"binary\",  # For binary classification (0 and 1)\n",
    "    batch_size=32,  # Set your batch size\n",
    "    image_size=(224, 224),  # Resize images to a consistent size (e.g., 224x224)\n",
    "    shuffle=True,  # Shuffle the dataset\n",
    "    seed=42  # Set a seed for reproducibility\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"FRAMES/test_frames/\",\n",
    "    labels=\"inferred\",  # Automatically labels based on subdirectory names\n",
    "    label_mode=\"binary\",  # For binary classification (0 and 1)\n",
    "    batch_size=32,  # Set your batch size\n",
    "    image_size=(224, 224),  # Resize images to a consistent size (e.g., 224x224)\n",
    "    shuffle=False,\n",
    "    seed=42  # Set a seed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CL-hzC4WbTtv",
    "outputId": "7f28e3a4-3d9f-42a6-d668-c8fc81c3e774"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.class_names == test_dataset.class_names == val_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5V2P-sOAyJV"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    create_resnet_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=4,\n",
    "    executions_per_trial=1,\n",
    "    directory='DIR',\n",
    "    project_name='Resnet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfNFIFwmcFMz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "# Create a CSVLogger callback\n",
    "csv_logger = CSVLogger('tuning_loss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYsMR7h5bgY6",
    "outputId": "669cfbda-27a0-406b-c01c-3f2647165d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [02h 17m 51s]\n",
      "val_loss: 0.6931371092796326\n",
      "\n",
      "Best val_loss So Far: 0.3929249346256256\n",
      "Total elapsed time: 05h 45m 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 122 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Start the hyperparameter search\n",
    "tuner.search(train_dataset, epochs=3, validation_data=val_dataset, callbacks=[csv_logger])\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMu_2Urtd7rQ",
    "outputId": "6891e13e-67c8-418e-abf8-965316997ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m33197/33197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2775s\u001b[0m 83ms/step - accuracy: 0.9261 - loss: 0.1762 - val_accuracy: 0.8434 - val_loss: 0.4278\n",
      "Epoch 2/7\n",
      "\u001b[1m33197/33197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2747s\u001b[0m 83ms/step - accuracy: 0.9574 - loss: 0.1066 - val_accuracy: 0.8571 - val_loss: 0.3595\n",
      "Epoch 3/7\n",
      "\u001b[1m33197/33197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2741s\u001b[0m 83ms/step - accuracy: 0.9694 - loss: 0.0789 - val_accuracy: 0.8725 - val_loss: 0.3994\n",
      "Epoch 4/7\n",
      "\u001b[1m33197/33197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2731s\u001b[0m 82ms/step - accuracy: 0.9752 - loss: 0.0642 - val_accuracy: 0.8734 - val_loss: 0.4896\n",
      "Epoch 5/7\n",
      "\u001b[1m33197/33197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2734s\u001b[0m 82ms/step - accuracy: 0.9787 - loss: 0.0553 - val_accuracy: 0.8707 - val_loss: 0.4800\n",
      "Epoch 6/7\n",
      "\u001b[1m33197/33197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2735s\u001b[0m 82ms/step - accuracy: 0.9815 - loss: 0.0485 - val_accuracy: 0.8737 - val_loss: 0.5309\n",
      "Epoch 7/7\n",
      "\u001b[1m33197/33197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2735s\u001b[0m 82ms/step - accuracy: 0.9835 - loss: 0.0438 - val_accuracy: 0.8656 - val_loss: 0.5173\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'best_model.keras', save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "history = best_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=7,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load the best model from the file\n",
    "from tensorflow.keras.models import load_model\n",
    "best_model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "gvME0_5GLyAR",
    "outputId": "59ade153-012b-4547-8a41-334c81c0e244"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_1bb306c4-f22c-45a8-b01e-2112caec0386\", \"training_loss.csv\", 325)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "training_loss = pd.DataFrame({'Epoch': range(len(loss)), \"Training Loss\": loss, \"Validation Loss\": val_loss})\n",
    "training_loss.to_csv(\"training_loss.csv\", index=False)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"tuning_loss.csv\")\n",
    "files.download(\"training_loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4N0PT4Wb99W"
   },
   "outputs": [],
   "source": [
    "best_model.save(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR3gCASQtDQ-"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "warfgCGJMS3P"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GBE-5Fd3a5n"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q tensorflow\n",
    "!pip install -U -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vU0GzHVi3Hw4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "best_model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTKyObgPKbbp",
    "outputId": "924b9c5f-aa23-40ea-cdf2-ecad46be3edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326064 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"FRAMES/test_frames/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,  # Don't shuffle is the diff here.\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6sqUBE0Gs89",
    "outputId": "d419fdc1-10fd-4868-8d1b-7a463356808d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10190/10190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2uFBejoI7Ib"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh3dJQMyIczC"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities = predictions.flatten()\n",
    "\n",
    "# Collect true labels and predicted labels\n",
    "true_labels_list = []\n",
    "predicted_probabilities_list = []\n",
    "\n",
    "for images, true_labels in test_dataset:\n",
    "    true_labels_list.extend(true_labels.numpy().flatten())  # Collect true labels\n",
    "    predicted_probabilities_list.extend(predicted_probabilities[:len(true_labels)])  # Collect predictions\n",
    "    predicted_probabilities = predicted_probabilities[len(true_labels):]  # Remove used predictions\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"actual_label\": true_labels_list,\n",
    "    \"predicted_probability\": predicted_probabilities_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "vENp65u7JTq5",
    "outputId": "7f81c280-4df9-4556-b91e-f9fb177b17a8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "results_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f0cb8f4e-1ead-40c9-a9e0-129fd2350d91\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326059</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326060</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326061</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326062</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326063</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326064 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0cb8f4e-1ead-40c9-a9e0-129fd2350d91')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f0cb8f4e-1ead-40c9-a9e0-129fd2350d91 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f0cb8f4e-1ead-40c9-a9e0-129fd2350d91');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-467708f7-3e48-415e-b16a-91c7cd3bb37f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-467708f7-3e48-415e-b16a-91c7cd3bb37f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-467708f7-3e48-415e-b16a-91c7cd3bb37f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_d55649de-5f41-4755-b8aa-2c6f68b2355f\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_d55649de-5f41-4755-b8aa-2c6f68b2355f button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('results_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        actual_label  predicted_probability\n",
       "0                0.0               0.014168\n",
       "1                0.0               0.012575\n",
       "2                0.0               0.008793\n",
       "3                0.0               0.015844\n",
       "4                0.0               0.037645\n",
       "...              ...                    ...\n",
       "326059           1.0               0.988267\n",
       "326060           1.0               0.977758\n",
       "326061           1.0               0.989587\n",
       "326062           1.0               0.986530\n",
       "326063           1.0               0.990135\n",
       "\n",
       "[326064 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Nk7kBYjeUGY"
   },
   "source": [
    "Now we convert the frame-level predictions to video-level predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0_T58w5eXng",
    "outputId": "8309ba4b-5ec5-4718-b090-978a24335055"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [02:15<00:00,  4.06it/s]\n",
      "100%|██████████| 550/550 [01:59<00:00,  4.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_image(file_name):\n",
    "  raw = tf.io.read_file(file_name)\n",
    "  tensor = tf.io.decode_image(raw)\n",
    "  tensor = tf.cast(tensor, tf.float32)\n",
    "  return tensor\n",
    "\n",
    "\n",
    "def create_dataset(file_names, vidlabel):\n",
    "  labels = [vidlabel] * len(file_names)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((file_names, labels))\n",
    "  dataset = dataset.map(lambda file_name, label: (load_image(file_name), label))\n",
    "  return dataset.batch(32)\n",
    "\n",
    "deep = \"./FRAMES/test_frames/deepfake/\"\n",
    "deepfaked_vids = os.listdir(deep)\n",
    "real = \"./FRAMES/test_frames/real/\"\n",
    "real_vids = os.listdir(real)\n",
    "\n",
    "def predict(label=0):\n",
    "    p = []\n",
    "    if not label:\n",
    "        vids = deepfaked_vids\n",
    "        pth = deep\n",
    "    else:\n",
    "        vids = real_vids\n",
    "        pth = real\n",
    "\n",
    "    for vid in tqdm(vids):\n",
    "        images = [os.path.join(pth+vid, fname) for fname in os.listdir(pth+vid)\n",
    "        if fname.lower().endswith('.jpg')]\n",
    "        video = create_dataset(images, label)\n",
    "        p.append(np.mean(best_model.predict(video, verbose=0)))\n",
    "    return p\n",
    "\n",
    "predictions_for_real = predict(1)\n",
    "predictions_for_deep = predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofgoGaMNqmf1"
   },
   "outputs": [],
   "source": [
    "predictions_for_real = np.array(predictions_for_real)\n",
    "predictions_for_deep = np.array(predictions_for_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NznbMdPK73wo"
   },
   "outputs": [],
   "source": [
    "df_real = pd.DataFrame({'predicted_probability': predictions_for_real})\n",
    "df_deep = pd.DataFrame({'predicted_probability': predictions_for_deep})\n",
    "df_real['actual_label'] = [1.0 for i in range(len(df_real))]\n",
    "df_deep['actual_label'] = [0.0 for i in range(len(df_deep))]\n",
    "\n",
    "df = pd.concat([df_real, df_deep])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVfwe6youDo3"
   },
   "outputs": [],
   "source": [
    "# Above, we had 0 = deepfake and 1 = real instead of 0 = real and 1 = deepfake like the other models\n",
    "# This discrepancy was only realised after model training had begun\n",
    "# To correct for this error, we correct the results.csv\n",
    "\n",
    "corrected_df = 1 - df\n",
    "corrected_df.to_csv('resnet_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
