{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_eQGxvd8aRy",
    "outputId": "b45727ae-f9e1-4723-b6e1-6175ae4eba8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQW7Z76Z876u"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_--KKUy18pzu"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PbUu7NiA09Q",
    "outputId": "c0c09f2e-9699-4d2a-945e-373d9924fdd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.3)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_AF92NTo5aw"
   },
   "source": [
    "Let's now count the number of total videos we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oJMAZqE-HavC"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_root_path = pathlib.Path(\"./drive/MyDrive/DSA4266 Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbqX2rHF_NsJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZRB1yJQHm5W",
    "outputId": "5dd447a1-47f8-4a6f-e9bb-8215b581d2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos: 5500\n"
     ]
    }
   ],
   "source": [
    "video_count_train = len(list(dataset_root_path.glob(\"train/*/*.mp4\")))\n",
    "video_count_val = len(list(dataset_root_path.glob(\"validation/*/*.mp4\")))\n",
    "video_count_test = len(list(dataset_root_path.glob(\"test/*/*.mp4\")))\n",
    "video_total = video_count_train + video_count_val + video_count_test\n",
    "print(f\"Total videos: {video_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNUCBLe6HoLY",
    "outputId": "4f8965cf-26e1-4baf-f529-5204861ff354"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lbooddsyfl.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lbpfomllae.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lcmjyjdbqn.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lclyxqctwg.mp4'),\n",
       " PosixPath('drive/MyDrive/DSA4266 Project/train/deepfake/lcegpefqvk.mp4')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_video_file_paths = (\n",
    "    list(dataset_root_path.glob(\"train/*/*.mp4\"))\n",
    "    + list(dataset_root_path.glob(\"validation/*/*.mp4\"))\n",
    "    + list(dataset_root_path.glob(\"test/*/*.mp4\"))\n",
    ")\n",
    "all_video_file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeWXvJSDHpbw",
    "outputId": "ad136bad-3fa8-4fbf-9927-c552d75ff8ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: ['deepfake', 'real'].\n"
     ]
    }
   ],
   "source": [
    "class_labels = sorted({str(path).split(\"/\")[4] for path in all_video_file_paths})\n",
    "label2id = {label: i for i, label in enumerate(class_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(f\"Unique classes: {list(label2id.keys())}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6qmNcvQpXwW"
   },
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "45iXS1i-4JgV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# Define CNN model architecture with skip connections\n",
    "\n",
    "def conv_block(x, filter):\n",
    "    # Layer 1\n",
    "    x_skip = x\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])    # Skip connection\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def create_resnet_model(hp):\n",
    "    strides = hp.Int('strides', min_value=1, max_value=3, step=2)\n",
    "    kernel_size = hp.Int('kernel_size', min_value=3, max_value=5, step=2)\n",
    "    filters = 64\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(inputs) # add padding\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x) # always doing this\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=strides, padding='same')(x)\n",
    "\n",
    "    # number of filters will increase deeper into the model\n",
    "    for i in range(5):\n",
    "        filters = filters << 1\n",
    "        x = conv_block(x, filters)\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid')(x)  # binary\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']) # always use adam\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    # model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Jk8UwWTDHtC",
    "outputId": "e374b691-33eb-4cf6-f84c-e5d234401b0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1788/1788 [14:37<00:00,  2.04it/s]\n",
      "100%|██████████| 1788/1788 [13:44<00:00,  2.17it/s]\n",
      "100%|██████████| 550/550 [03:35<00:00,  2.55it/s]\n",
      "100%|██████████| 550/550 [03:20<00:00,  2.75it/s]\n",
      "100%|██████████| 412/412 [02:30<00:00,  2.73it/s]\n",
      "100%|██████████| 412/412 [02:31<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Functions adapted from Junhui's cnn_dev.ipynb\n",
    "# (Print statements removed to allow tqdm to work)\n",
    "\n",
    "pth = \"./drive/MyDrive/DSA4266 Project/\"\n",
    "\n",
    "\n",
    "def load_video(video_name, folder_path=\"../../data/train_sample_videos\"):\n",
    "    video_path = os.path.join(folder_path, video_name)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    return cap\n",
    "\n",
    "\n",
    "def extract_frames(cap, frame_interval=1):\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            resized_frame = cv2.resize(frame, (224, 224)) / 255.0\n",
    "            frames.append(resized_frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def save_frames(frames, output_folder=\"./extracted_frames\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for frame_count, frame in enumerate(frames):\n",
    "        output_path = os.path.join(output_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(output_path, (frame * 255).astype(\"uint8\"))\n",
    "\n",
    "\n",
    "def extract_and_save_videos(input_dir, output_dir):\n",
    "    filenames = sorted(os.listdir(input_dir))\n",
    "    for filename in tqdm(filenames):\n",
    "        if not filename.endswith((\".mp4\")):\n",
    "            continue\n",
    "        cap = load_video(filename, input_dir)\n",
    "        frames = extract_frames(cap)\n",
    "        video_output_dir = os.path.join(output_dir, filename[:-4])\n",
    "        save_frames(frames, video_output_dir)\n",
    "\n",
    "categories = [\"train\", \"test\", \"validation\"]\n",
    "for cat in categories:\n",
    "    extract_and_save_videos(f\"{pth}{cat}/deepfake\", f\"FRAMES/{cat}_frames/deepfake\")\n",
    "    extract_and_save_videos(f\"{pth}{cat}/real\", f\"FRAMES/{cat}_frames/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5V2P-sOAyJV"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    create_resnet_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=4,\n",
    "    executions_per_trial=1,\n",
    "    directory='DIR',\n",
    "    project_name='Resnet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOMos0CAeG1k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Any, Callable, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def rotate_frame(frame: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rotates the given `frame` by the angle `angle`.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Original frame to be transformed.\n",
    "        angle (float): Angle to rotate the frame by.\n",
    "\n",
    "    Returns:\n",
    "        Rotated array of type `np.ndarray`.\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(frame, matrix, (width, height))\n",
    "    return rotated\n",
    "\n",
    "\n",
    "def adjust_brightness_contrast(\n",
    "    frame: np.ndarray, brightness: float = 0.0, contrast: float = 0.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adjusts the brightness and contrast of a frame.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Original frame to be transformed.\n",
    "        brightness (float): Amount to increase the brightness by.\n",
    "        contrast (float): Amount fo increase the contrast by.\n",
    "\n",
    "    Returns:\n",
    "        Modified array of type `np.ndarray`.\n",
    "    \"\"\"\n",
    "    frame = np.clip(frame * (1 + contrast / 100.0) + brightness, 0, 255).astype(\n",
    "        np.uint8\n",
    "    )\n",
    "    return frame\n",
    "\n",
    "\n",
    "def flip_frame(frame: np.ndarray, flip_code: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flips the frame.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Original frame to be transformed.\n",
    "        flip_code (int): Flip code; 1 for vertical flip and 0 for horizontal flip.\n",
    "\n",
    "    Returns:\n",
    "        Flipped frame of type `np.ndarray`.\n",
    "    \"\"\"\n",
    "    return cv2.flip(frame, flip_code)\n",
    "\n",
    "\n",
    "def transform(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    transformation: Callable[[np.ndarray, Optional[Any], Optional[Any]], np.ndarray],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Applies a single random transformation to the frame, then saves the result.\n",
    "    Note that there is an identity transformation which keeps the frame the same.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Input path as a string.\n",
    "        output_path (str): Output path as a string.\n",
    "        transformation (Callable[[np.ndarray], np.ndarray])\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    frame = cv2.imread(input_path)\n",
    "    transformed_frame = transformation(frame)\n",
    "    transformed_frame = transformed_frame.astype(np.uint8)\n",
    "    cv2.imwrite(output_path, transformed_frame)\n",
    "\n",
    "\n",
    "def augment_frame(\n",
    "    input_dir: str | bytes | os.PathLike,\n",
    "    output_dir: str | bytes | os.PathLike,\n",
    "    filename: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Augments the frame by applying one random transformation and saves it.\n",
    "    Note that there is an identity transformation which keeps the frame the same.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str | bytes | os.PathLike): Input directory.\n",
    "        output_dir (str | bytes | os.PathLike): Output directory.\n",
    "        filename (str): File to be augmented.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    transformations = [\n",
    "        lambda frame: frame,\n",
    "        lambda frame: rotate_frame(frame, 90),\n",
    "        lambda frame: rotate_frame(frame, 180),\n",
    "        lambda frame: rotate_frame(frame, 270),\n",
    "        lambda frame: adjust_brightness_contrast(frame, brightness=-25),\n",
    "        lambda frame: adjust_brightness_contrast(frame, brightness=25),\n",
    "        lambda frame: adjust_brightness_contrast(frame, contrast=-25),\n",
    "        lambda frame: adjust_brightness_contrast(frame, contrast=25),\n",
    "        lambda frame: flip_frame(frame, 1),\n",
    "        lambda frame: flip_frame(frame, 0),\n",
    "    ]\n",
    "\n",
    "    transformation_fn = random.choice(transformations)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    transform(input_path, output_path, transformation_fn)\n",
    "\n",
    "\n",
    "def augment_frames(\n",
    "    input_dir: str | bytes | os.PathLike, output_dir: str | bytes | os.PathLike\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Augments frames by applying a random augmentation to each one.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str | bytes | os.PathLike): Input directory containing the original frames.\n",
    "        output_dir (str | bytes | os.PathLike): Output directory to save the augmented frames to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    filenames = sorted(os.listdir(input_dir))\n",
    "    random.seed(42)\n",
    "    for filename in tqdm(filenames):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        video_dir = os.path.join(input_dir, filename)\n",
    "        video_output_dir = os.path.join(output_dir, filename)\n",
    "        frames = sorted(os.listdir(video_dir))\n",
    "        for frame in frames:\n",
    "            augment_frame(video_dir, video_output_dir, frame)\n",
    "\n",
    "\n",
    "categories = [\"train\", \"validation\"]\n",
    "for cat in categories:\n",
    "    augment_frames(\n",
    "        f\"FRAMES/{cat}_frames/deepfake\", f\"AUGMENTED/{cat}_frames_augmented/deepfake\"\n",
    "    )\n",
    "    augment_frames(f\"FRAMES/{cat}_frames/real\", f\"AUGMENTED/{cat}_frames_augmented/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RhgHJ0WZ8UF"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"AUGMENTED/train_frames_augmented/\",\n",
    "    labels=\"inferred\",  # Automatically labels based on subdirectory names\n",
    "    label_mode=\"binary\",  # For binary classification (0 and 1)\n",
    "    batch_size=32,  # Set your batch size\n",
    "    image_size=(224, 224),  # Resize images to a consistent size (e.g., 224x224)\n",
    "    shuffle=True,  # Shuffle the dataset\n",
    "    seed=42  # Set a seed for reproducibility\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"AUGMENTED/validation_frames_augmented/\",\n",
    "    labels=\"inferred\",  # Automatically labels based on subdirectory names\n",
    "    label_mode=\"binary\",  # For binary classification (0 and 1)\n",
    "    batch_size=32,  # Set your batch size\n",
    "    image_size=(224, 224),  # Resize images to a consistent size (e.g., 224x224)\n",
    "    shuffle=True,  # Shuffle the dataset\n",
    "    seed=42  # Set a seed for reproducibility\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"FRAMES/test_frames/\",\n",
    "    labels=\"inferred\",  # Automatically labels based on subdirectory names\n",
    "    label_mode=\"binary\",  # For binary classification (0 and 1)\n",
    "    batch_size=32,  # Set your batch size\n",
    "    image_size=(224, 224),  # Resize images to a consistent size (e.g., 224x224)\n",
    "    shuffle=False,\n",
    "    seed=42  # Set a seed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CL-hzC4WbTtv"
   },
   "outputs": [],
   "source": [
    "train_dataset.class_names == test_dataset.class_names == val_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYsMR7h5bgY6"
   },
   "outputs": [],
   "source": [
    "# Start the hyperparameter search\n",
    "tuner.search(train_dataset, epochs=3, validation_data=val_dataset)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMu_2Urtd7rQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'best_model.keras', save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min'\n",
    ")\n",
    "\n",
    "history = best_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=7,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Load the best model from the file\n",
    "from tensorflow.keras.models import load_model\n",
    "best_model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4N0PT4Wb99W"
   },
   "outputs": [],
   "source": [
    "best_model.save(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR3gCASQtDQ-"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "warfgCGJMS3P"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GBE-5Fd3a5n",
    "outputId": "21ec41c3-d26e-403c-ac27-280b6281afd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U -q tensorflow\n",
    "!pip install -U -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vU0GzHVi3Hw4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "best_model = load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTKyObgPKbbp",
    "outputId": "e9f4d4fa-de35-44a5-f854-41d7aec5a003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326064 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"FRAMES/test_frames/\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,  # Don't shuffle is the diff here.\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6sqUBE0Gs89",
    "outputId": "9cee2e62-a348-4944-ec53-6ce9d2d40411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10190/10190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2527s\u001b[0m 246ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "H2uFBejoI7Ib"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh3dJQMyIczC"
   },
   "outputs": [],
   "source": [
    "predicted_labels = predictions.flatten()\n",
    "\n",
    "# Collect true labels and predicted labels\n",
    "true_labels_list = []\n",
    "predicted_labels_list = []\n",
    "\n",
    "for images, true_labels in test_dataset:\n",
    "    true_labels_list.extend(true_labels.numpy().flatten())  # Collect true labels\n",
    "    predicted_labels_list.extend(predicted_labels[:len(true_labels)])  # Collect predictions\n",
    "    predicted_labels = predicted_labels[len(true_labels):]  # Remove used predictions\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"actual_label\": true_labels_list,\n",
    "    \"predicted_probability\": predicted_labels_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "vENp65u7JTq5",
    "outputId": "1903b2fb-6de3-4ef4-9818-38dbdcb0e328"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "results_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6bd02912-b92e-494a-9b78-f851aa863e98\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326059</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326060</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326061</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326062</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326063</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326064 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bd02912-b92e-494a-9b78-f851aa863e98')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6bd02912-b92e-494a-9b78-f851aa863e98 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6bd02912-b92e-494a-9b78-f851aa863e98');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3bee80c8-7994-4053-aa7f-9c97dbcbcafe\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3bee80c8-7994-4053-aa7f-9c97dbcbcafe')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3bee80c8-7994-4053-aa7f-9c97dbcbcafe button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_ac02f49e-2368-4215-a377-a869bf0f259e\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_ac02f49e-2368-4215-a377-a869bf0f259e button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('results_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        actual_label  predicted_probability\n",
       "0                0.0               0.005769\n",
       "1                0.0               0.000804\n",
       "2                0.0               0.000416\n",
       "3                0.0               0.000193\n",
       "4                0.0               0.000956\n",
       "...              ...                    ...\n",
       "326059           1.0               0.999999\n",
       "326060           1.0               0.999977\n",
       "326061           1.0               0.999736\n",
       "326062           1.0               0.999111\n",
       "326063           1.0               0.998422\n",
       "\n",
       "[326064 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Nk7kBYjeUGY"
   },
   "source": [
    "That was just on frames, now on video which is the main mission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0_T58w5eXng",
    "outputId": "d798f1b8-fb45-47cd-cab9-c3c56b41470b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [24:12<00:00,  2.64s/it]\n",
      "100%|██████████| 550/550 [22:18<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_image(file_name):\n",
    "  raw = tf.io.read_file(file_name)\n",
    "  tensor = tf.io.decode_image(raw)\n",
    "  tensor = tf.cast(tensor, tf.float32)\n",
    "  return tensor\n",
    "\n",
    "\n",
    "def create_dataset(file_names, vidlabel):\n",
    "  labels = [vidlabel] * len(file_names)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((file_names, labels))\n",
    "  dataset = dataset.map(lambda file_name, label: (load_image(file_name), label))\n",
    "  return dataset.batch(32)\n",
    "\n",
    "deep = \"./FRAMES/test_frames/deepfake/\"\n",
    "deepfaked_vids = os.listdir(deep)\n",
    "real = \"./FRAMES/test_frames/real/\"\n",
    "real_vids = os.listdir(real)\n",
    "\n",
    "def predict(label=0):\n",
    "    p = []\n",
    "    if not label:\n",
    "        vids = deepfaked_vids\n",
    "        pth = deep\n",
    "    else:\n",
    "        vids = real_vids\n",
    "        pth = real\n",
    "\n",
    "    for vid in tqdm(vids):\n",
    "        images = [os.path.join(pth+vid, fname) for fname in os.listdir(pth+vid)\n",
    "        if fname.lower().endswith('.jpg')]\n",
    "        video = create_dataset(images, label)\n",
    "        p.append(np.mean(best_model.predict(video, verbose=0)))\n",
    "    return p\n",
    "\n",
    "predictions_for_real = predict(1)\n",
    "predictions_for_deep = predict(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ofgoGaMNqmf1"
   },
   "outputs": [],
   "source": [
    "predictions_for_real = np.array(predictions_for_real)\n",
    "predictions_for_deep = np.array(predictions_for_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NznbMdPK73wo"
   },
   "outputs": [],
   "source": [
    "df_real = pd.DataFrame({'predicted_probability': predictions_for_real})\n",
    "df_deep = pd.DataFrame({'predicted_probability': predictions_for_deep})\n",
    "df_real['actual_label'] = [1.0 for i in range(len(df_real))]\n",
    "df_deep['actual_label'] = [0.0 for i in range(len(df_deep))]\n",
    "\n",
    "df = pd.concat([df_real, df_deep])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVfwe6youDo3"
   },
   "outputs": [],
   "source": [
    "# Above, we had 0 = deepfake and 1 = real instead of 0 = real and 1 = deepfake like the other models\n",
    "# This discrepancy was only realised after model training had begun\n",
    "# To correct for this error, we correct the results.csv\n",
    "\n",
    "corrected_df = 1 - df\n",
    "corrected_df.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
